{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Building Dialog Structure from Two‑Channel Speech Data\n",
    "\n",
    "This notebook walks you through taking the word‑level transcripts and laughter probabilities you generated earlier to build a structured dialogue table for personality prediction.\n",
    "\n",
    "> **Before you begin:**  \n",
    "> Run all previous preprocessing notebooks before proceeding.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# from pathlib import Path\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../sho_util/pyfiles/\")\n",
    "from basic import get_bool_base_on_conditions\n",
    "\n",
    "sys.path.append('./../../../laughter-detection/')\n",
    "import laugh_segmenter\n",
    "\n",
    "sys.path.append('../pyfiles/')\n",
    "from dialog import save_audio, EnglishTextNormalizer, update_information, concatenate_close_voice, delete_fully_overlap, get_timeshifted_for_overlap, get_sentence_start, get_fully_overlap\n",
    "\n",
    "tempfile = \"temp.wav\"\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 504)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "normalizer = EnglishTextNormalizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "In this example, we will preprocess the transcriptions and laughter probabilities and construct a dialog table, which will be used for personality prediction. Please adjust the following variables:\n",
    "\n",
    "- `audiopath`: A string containing the path to the two‑channel speech file.  \n",
    "- `feature_dir`: A string specifying the path of the directory where all preprocessed results will be saved.  \n",
    "- `sr`: An integer specifying the sampling rate used in silent section detection.  \n",
    "\n",
    "We also provide several editable parameters for laughter detection, silent-section removal, and dialog construction. The default values were chosen based on our experiments and the literature, so we recommend keeping them as is—but feel free to adjust if needed.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################\n",
      "### Load all data ###\n",
      "#####################\n",
      "##########################\n",
      "### delete silent sections\n",
      "##########################\n",
      "#############################\n",
      "##### Laughter Analysis #####\n",
      "#############################\n",
      "###########################################################\n",
      "### Preprocess the word-level time stamp into sentences ###\n",
      "###########################################################\n",
      "#########################################\n",
      "### Get Dialog with Shifted Timestamp ###\n",
      "#########################################\n",
      "######################################\n",
      "### Get Candidates of Backchannels ###\n",
      "######################################\n",
      "#######################################\n",
      "### Get Candidates of Interjections ###\n",
      "#######################################\n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "########## Adjustable Parameters ##########\n",
    "###########################################\n",
    "\n",
    "audiopath = \"../audio/sample.wav\"\n",
    "feature_dir = \"../audio/features/sample/\"\n",
    "sr = 16000 \n",
    "\n",
    "#################################################\n",
    "##### Editable Parameters (Not recommended) #####\n",
    "#################################################\n",
    "\n",
    "### Silent section deletion\n",
    "minimum_length = 0.01\n",
    "top_db = 15\n",
    "trim_window = 256\n",
    "trim_stride = 128\n",
    "\n",
    "### Laughter Analysis\n",
    "\n",
    "# The following two variables are used in the laughter detection. I recommend the following default values but feel free to change it if necessary.\n",
    "threshold = 0.5 \n",
    "min_length = 0.2\n",
    "\n",
    "include_laughter = True\n",
    "always_word_timestamp = True # We include the laughter tokens but the time stamp follows the word ones. \n",
    "exclude_short_laughs = False\n",
    "\n",
    "### Dialog Generation\n",
    "concatenation_threshold1 = 0.7 # [s] the threshold duration whether we concatenate the consecutive transcriptions (this is used to connect words to construct a sentence)\n",
    "# turn-taking\n",
    "thres_duration_fo = np.inf # [s] the threshold duration to be deleted when they have fully-overlaps.\n",
    "thres_overlap_timeshift = concatenation_threshold1 # [s] threshold that allows different speakers to do overlap [s]. The following utterances will be shifted in the overlapped time.\n",
    "concatenation_threshold2 = concatenation_threshold1 # [s] the threshold duration whether we concatenate the consecutive transcriptions\n",
    "thres_sentence_length = 3.0 # [s] the minimum silent length in a single conversation\n",
    "# backchannel\n",
    "fully_margin_interjection = 0.0\n",
    "backchannel_threshold = np.inf\n",
    "# controlling interjection\n",
    "margin_interjection = concatenation_threshold1\n",
    "minimum_duration_ci = 0.0\n",
    "\n",
    "backchannel_dict = {\n",
    "    \"emotive\": [\n",
    "        \"wow\", \"ouch\", \"yay\", \"ew\", \"ooh\", \"phew\", \"ugh\", \"aha\", \"eek\", \"really\", \"sorry\", \"oh really\", \n",
    "        \"[Laugh]\", \"oh\",\n",
    "    ],\n",
    "    \"cognitive\": [\n",
    "        \"okay\", \"mm hmm\", \"true\", \"ok\", \"mm hmm, exactly\", \"exactly\", \"certainly\", \"absolutely\",\n",
    "        \"oh i see\", \"mm\", \"hmm\", \"ah\", \"mm hmm exactly\", \"yeah\", \"right\", \"true okay\", \"well\", \"um\", \n",
    "        \"let's see\", \"oh yeah\", \"yes\", \"sure\", \"absolutely yeah\", \"yep\", \"that's right\", \"uh huh\",\n",
    "        \"oh okay\", \"you think\", \"yeah uh huh\", \"uh huh yeah\", \"mm hmm yeah\", \"yeah mm hmm\", \"that's true\"\n",
    "    ],\n",
    "}\n",
    "nocontolling_list =  []\n",
    "\n",
    "################################################################################\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "print(\"#####################\")\n",
    "print(\"### Load all data ###\")\n",
    "print(\"#####################\")\n",
    "resultpath = feature_dir + \"whisper/\" + os.path.basename(audiopath[:-4]) + f\".npy\"\n",
    "laughpath = feature_dir + \"laughs/\" + os.path.basename(audiopath[:-4]) + f\".npy\"\n",
    "tablepath = laughpath.replace(\"laughs\", \"results\")\n",
    "\n",
    "a, _ = librosa.load(audiopath, sr=sr, mono=False)\n",
    "audio = []\n",
    "for i in range(2):\n",
    "    save_audio(tempfile, a[i], sr)\n",
    "    audio += [librosa.load(tempfile, sr=sr)[0]]\n",
    "audio += [librosa.load(audiopath, sr=sr)[0]]\n",
    "\n",
    "results = [None, None]\n",
    "results[0], results[1] = np.load(resultpath, allow_pickle=True)\n",
    "for ch in range(2):\n",
    "    a = results[ch][\"segments\"]\n",
    "    for i in range(len(a)):\n",
    "        b = a[i][\"words\"]\n",
    "        for j in range(len(b)):\n",
    "            text = b[j][\"word\"]\n",
    "            results[ch][\"segments\"][i][\"words\"][j][\"word\"] = normalizer(text)\n",
    "\n",
    "a = np.load(laughpath)\n",
    "fps = a[0][0]\n",
    "probs = a[:, 1:]\n",
    "laughs = []\n",
    "for i in range(2):\n",
    "    laugh = laugh_segmenter.get_laughter_instances(probs[i], threshold=threshold, min_length=float(min_length), fps=fps)\n",
    "    laughs += [np.round(np.array(laugh), 2)]\n",
    "\n",
    "print(\"##########################\")\n",
    "print(\"### delete silent sections\")\n",
    "print(\"##########################\")\n",
    "texts = []\n",
    "for j in range(2):\n",
    "    texts += [[]]\n",
    "    for i in range(len(results[j][\"segments\"])):\n",
    "        texts[j] += results[j][\"segments\"][i][\"words\"] \n",
    "    texts[j] = {a[\"start\"]:a for a in texts[j]}\n",
    "\n",
    "newtexts = []\n",
    "for ch in range(2):\n",
    "    text = texts[ch]\n",
    "    newtext = {}\n",
    "    # for key in tqdm(text):\n",
    "    for key in text:\n",
    "        array = text[key]\n",
    "        start = array[\"start\"]\n",
    "        end = array[\"end\"]\n",
    "        segment = audio[ch][int(sr*start):int(sr*end)]\n",
    "        _, spans = librosa.effects.trim(segment, top_db=top_db, frame_length=trim_window, hop_length=trim_stride)\n",
    "        newstart, newend = start + spans/sr\n",
    "        if newend-newstart<minimum_length:\n",
    "            continue\n",
    "        newtext[newstart] = {\n",
    "            \"word\": array[\"word\"],\n",
    "            \"start\": newstart,\n",
    "            \"end\": newend,\n",
    "            \"probability\": array[\"probability\"],\n",
    "        }\n",
    "    newtexts += [newtext]\n",
    "texts = newtexts\n",
    "\n",
    "starts, ends = [], []\n",
    "for i in range(2):\n",
    "    starts += [np.array(list(texts[i].keys()))]\n",
    "    ends += [np.array([texts[i][key][\"end\"] for key in texts[i]])]\n",
    "\n",
    "print(\"#############################\")\n",
    "print(\"##### Laughter Analysis #####\")\n",
    "print(\"#############################\")\n",
    "\n",
    "if include_laughter:\n",
    "    ### Initialization\n",
    "    startlaughs, endlaughs = [], []\n",
    "    for i in range(2):\n",
    "        if len(laughs[i])==0:\n",
    "            startlaughs += [np.array([])]\n",
    "            endlaughs += [np.array([])]\n",
    "            continue\n",
    "        startlaughs += [np.array(laughs[i])[:,0]]\n",
    "        endlaughs += [np.array(laughs[i])[:,1]]\n",
    "\n",
    "        bl = startlaughs[i]<starts[i][-1]\n",
    "        startlaughs[i] = startlaughs[i][bl]\n",
    "        endlaughs[i] = endlaughs[i][bl]\n",
    "\n",
    "        bl = endlaughs[i]>ends[i][-1]\n",
    "        endlaughs[i][bl] = ends[i][-1]\n",
    "\n",
    "    for cl in range(2):\n",
    "        if len(laughs[cl])==0:\n",
    "            continue\n",
    "\n",
    "        ### Determine Short Laughs without Overlap to Words\n",
    "        a = starts[cl].reshape(1, -1)-startlaughs[cl].reshape(-1, 1)\n",
    "        a[a<0] = np.inf\n",
    "        indices = np.argmin(a, axis=1)\n",
    "\n",
    "        shortlaugh = starts[cl][indices]>endlaughs[cl]\n",
    "        for idx in np.arange(len(shortlaugh))[shortlaugh]:\n",
    "            start = startlaughs[cl][idx]\n",
    "            if always_word_timestamp:\n",
    "                end = start + 0.01\n",
    "            else:\n",
    "                end = endlaughs[cl][idx]\n",
    "            if not(exclude_short_laughs):\n",
    "                texts[cl][start] = {\"word\": '[Laugh]', \"start\": start, \"end\": end, \"probability\": 0.8, }\n",
    "\n",
    "        ### Update\n",
    "        bl = (1-shortlaugh).astype(bool)\n",
    "        startlaughs[cl] = startlaughs[cl][bl]\n",
    "        endlaughs[cl] = endlaughs[cl][bl]\n",
    "\n",
    "        shift = 0\n",
    "        while True:\n",
    "            ### When the end of laugh is within the spoken word\n",
    "            a = starts[cl].reshape(1, -1)-startlaughs[cl].reshape(-1, 1)\n",
    "            a[a<0] = np.inf\n",
    "            indices = np.argmin(a, axis=1)\n",
    "            getlaughs = ends[cl][indices+shift]>=endlaughs[cl]\n",
    "            # print(getlaughs)\n",
    "            for idx in np.arange(len(getlaughs))[getlaughs]:\n",
    "                if always_word_timestamp:\n",
    "                    start = starts[cl][indices][idx]-0.01\n",
    "                else:\n",
    "                    start = startlaughs[cl][idx]\n",
    "                end = starts[cl][indices][idx]\n",
    "                texts[cl][start] = {\"word\": '[StartLaugh]', \"start\": start, \"end\": end, \"probability\": 0.8, }\n",
    "\n",
    "                start = ends[cl][indices+shift][idx]\n",
    "                end = start\n",
    "                texts[cl][start] = {\"word\": '[EndLaugh]', \"start\": start, \"end\": end, \"probability\": 0.8, }\n",
    "\n",
    "            ### Update\n",
    "            bl = (1-getlaughs).astype(bool)\n",
    "            startlaughs[cl] = startlaughs[cl][bl]\n",
    "            endlaughs[cl] = endlaughs[cl][bl]\n",
    "            if len(startlaughs[cl])<=0:\n",
    "                break\n",
    "\n",
    "\n",
    "            ### When the end of laugh is in the silent section\n",
    "            a = starts[cl].reshape(1, -1)-startlaughs[cl].reshape(-1, 1)\n",
    "            a[a<0] = np.inf\n",
    "            indices = np.argmin(a, axis=1)\n",
    "            getlaughs = starts[cl][indices+shift+1]>endlaughs[cl]\n",
    "            for idx in np.arange(len(getlaughs))[getlaughs]:\n",
    "                # start = startlaughs[cl][idx]\n",
    "                start = starts[cl][indices][idx]-0.01\n",
    "                end = starts[cl][indices][idx]\n",
    "                texts[cl][start] = {\"word\": '[StartLaugh]', \"start\": start, \"end\": end, \"probability\": 0.8, }\n",
    "\n",
    "                start = ends[cl][indices+shift][idx]\n",
    "                if always_word_timestamp:\n",
    "                    end = ends[cl][indices+shift][idx]+0.01\n",
    "                else:\n",
    "                    end = endlaughs[cl][idx]\n",
    "                texts[cl][start] = {\"word\": '[EndLaugh]', \"start\": start, \"end\": end, \"probability\": 0.8, }\n",
    "\n",
    "            ### Update\n",
    "            bl = (1-getlaughs).astype(bool)\n",
    "            startlaughs[cl] = startlaughs[cl][bl]\n",
    "            endlaughs[cl] = endlaughs[cl][bl]\n",
    "            if len(startlaughs[cl])<=0:\n",
    "                break\n",
    "\n",
    "            shift += 1\n",
    "\n",
    "    newstart = []\n",
    "    for cl in range(2):\n",
    "        texts[cl] = dict(sorted(texts[cl].items()))\n",
    "        newstart += [np.array(list(texts[cl].keys()))]\n",
    "else:\n",
    "    newstart = starts\n",
    "\n",
    "print(\"###########################################################\")\n",
    "print(\"### Preprocess the word-level time stamp into sentences ###\")\n",
    "print(\"###########################################################\")\n",
    "\n",
    "arrays = []\n",
    "i, j = 0, 0\n",
    "while i<len(newstart[0]) and j<len(newstart[1]):\n",
    "    if newstart[0][i] <= newstart[1][j]:\n",
    "        arrays += [[*list(texts[0][newstart[0][i]].values())[:3], \"A\"]]\n",
    "        i += 1\n",
    "    else:\n",
    "        arrays += [[*list(texts[1][newstart[1][j]].values())[:3], \"B\"]]\n",
    "        j += 1\n",
    "\n",
    "# concatenation_threshold1: From previous literature, language generation takes 0.6 [s]\n",
    "data = pd.DataFrame(arrays, columns=[\"transcription\", \"start\", \"end\", \"speaker\"])\n",
    "data = data[[\"start\", \"end\", \"speaker\", \"transcription\"]]\n",
    "\n",
    "data = update_information(data, [\"\"])\n",
    "rawdata = data.copy()\n",
    "data = concatenate_close_voice(data, concatenation_threshold1, if_consecutive=False)\n",
    "data = update_information(data, [\"\"])\n",
    "original_data = data.copy() # \n",
    "\n",
    "print(\"#########################################\")\n",
    "print(\"### Get Dialog with Shifted Timestamp ###\")\n",
    "print(\"#########################################\")\n",
    "\n",
    "# Initialize Dialog\n",
    "data1 = original_data.copy()\n",
    "\n",
    "# Delete the fully-overlapped utterance\n",
    "data1 = delete_fully_overlap(data1, thres_duration_fo)\n",
    "data1 = update_information(data1, [\"\"])\n",
    "\n",
    "# Time Shifting based on Overlaps\n",
    "data1 = update_information(data1, [\"\"])\n",
    "data1 = get_timeshifted_for_overlap(data1, thres_overlap_timeshift)\n",
    "data1 = update_information(data1)\n",
    "\n",
    "startkey = \"start-timeshift\"\n",
    "endkey = \"end-timeshift\"\n",
    "btkey = \"duration-before-talking-timeshift\"\n",
    "overlapkey = \"Overlap-timeshift\"\n",
    "fokey = \"Fully-Overlap-timeshift\"\n",
    "\n",
    "# Concatenation of Close Voices from the same speaker\n",
    "data1 = concatenate_close_voice(data1, concatenation_threshold2, btkey, if_consecutive=True)\n",
    "data1 = update_information(data1)\n",
    "\n",
    "# Delete the fully-overlapped utterance and Concatenate again based on the deletion\n",
    "data1 = delete_fully_overlap(data1, thres_duration_fo, fokey=fokey)\n",
    "data1 = update_information(data1)\n",
    "data1 = concatenate_close_voice(data1, concatenation_threshold2, btkey, if_consecutive=True) \n",
    "data1 = update_information(data1)\n",
    "\n",
    "# Get Sentence Segmentation\n",
    "data1 = get_sentence_start(data1, thres_sentence_length)\n",
    "\n",
    "print(\"######################################\")\n",
    "print(\"### Get Candidates of Backchannels ###\")\n",
    "print(\"######################################\")\n",
    "\n",
    "# Initialize Dialog\n",
    "data2 = original_data.copy()\n",
    "\n",
    "data2 = concatenate_close_voice(data2, concatenation_threshold2, if_consecutive=False)\n",
    "data2 = update_information(data2, [\"\"], margin_fully_overlap=fully_margin_interjection)\n",
    "data2[\"BC-Candidates\"] = False\n",
    "bl = get_bool_base_on_conditions(data2, {\"Fully-Overlap\": [True]})*(data2[\"duration\"]<=backchannel_threshold)\n",
    "data2.loc[bl, \"BC-Candidates\"]  = True\n",
    "\n",
    "print(\"#######################################\")\n",
    "print(\"### Get Candidates of Interjections ###\")\n",
    "print(\"#######################################\")\n",
    "\n",
    "rawdata_dir = {\n",
    "    \"A\": rawdata[get_bool_base_on_conditions(rawdata, {\"speaker\": [\"A\"]})],\n",
    "    \"B\": rawdata[get_bool_base_on_conditions(rawdata, {\"speaker\": [\"B\"]})],\n",
    "}\n",
    "\n",
    "data3 = original_data.copy()\n",
    "data3 = update_information(data3, [\"\"], margin_overlap=margin_interjection)\n",
    "\n",
    "### Delete the fully-overlapped ones since it may not be the controlling interjection.\n",
    "fo = data3[get_bool_base_on_conditions(data3, {\"Fully-Overlap\": [True]})]\n",
    "for i in range(len(fo)):\n",
    "    array = fo.iloc[i]\n",
    "    idx = array.name\n",
    "    data3.loc[idx, \"Overlap\"] = \"\"\n",
    "    delol = int(array[\"Overlap\"].split(\"-\")[0])\n",
    "    arrayol = data3.loc[delol]\n",
    "    newol = []\n",
    "    for ol in arrayol[\"Overlap\"].split(\"-\"):\n",
    "        if ol!=str(idx):\n",
    "            newol += [ol]\n",
    "    newol = \"-\".join(newol)\n",
    "    data3.loc[delol, \"Overlap\"] = newol\n",
    "\n",
    "data3 = get_fully_overlap(data3)\n",
    "data3 = data3[(1-get_bool_base_on_conditions(data3, {\"Overlap\":[\"\"]})).astype(bool)]\n",
    "\n",
    "if len(data3)>0:\n",
    "\n",
    "    ### Split all sentences into words and Delete the common backchannels \n",
    "    df_list = []\n",
    "    for i in range(len(data3)):\n",
    "        array = data3.iloc[i]\n",
    "        speaker = array[\"speaker\"]\n",
    "        start = np.argmin(np.abs(rawdata_dir[speaker][\"start\"]-array[\"start\"]))\n",
    "        end = np.argmin(np.abs(rawdata_dir[speaker][\"end\"]-array[\"end\"]))\n",
    "        df_list += [rawdata_dir[speaker].iloc[start:end+1]]\n",
    "    dfci = pd.concat(df_list, axis=0)\n",
    "\n",
    "    texts = []\n",
    "    for i in range(len(dfci)):\n",
    "        array = dfci.iloc[i]\n",
    "        text = array[\"transcription\"]\n",
    "        a = \"\"\n",
    "        for key in backchannel_dict:\n",
    "            if text in backchannel_dict[key]:\n",
    "                texts += [key]\n",
    "                a = key\n",
    "                break\n",
    "        if text in nocontolling_list:\n",
    "            texts += [\"not controlling\"]\n",
    "            a = \"not controlling\"\n",
    "        if a==\"\":\n",
    "            texts += [\"\"]\n",
    "    dfci[\"BC-Labels\"] = texts\n",
    "    dfci = dfci[get_bool_base_on_conditions(dfci, {\"BC-Labels\": [\"\"]})]\n",
    "    dfci = dfci.sort_values(\"start\")\n",
    "    dfci = dfci.reset_index(drop=True)\n",
    "\n",
    "    if len(dfci)==0:\n",
    "        dfci = None\n",
    "    else:\n",
    "        dfci = dfci[[\"start\", \"end\", \"speaker\", \"transcription\"]]\n",
    "        dfci = update_information(dfci, [\"\"], margin_overlap=margin_interjection)\n",
    "        dfci = concatenate_close_voice(dfci, concatenation_threshold1, if_consecutive=False)\n",
    "        dfci = update_information(dfci, [\"\"], margin_overlap=margin_interjection)\n",
    "        dfci = dfci[(1-get_bool_base_on_conditions(dfci, {\"Overlap\":[\"\"]})).astype(bool)]\n",
    "\n",
    "        # Only get the interjections and delete the ones getting interjected\n",
    "        ci_list = []\n",
    "        fo = dfci.copy()\n",
    "        for i in range(len(fo)):\n",
    "            array = fo.iloc[i]\n",
    "            if array[\"Overlap\"]==\"\":\n",
    "                continue\n",
    "            idx = array.name\n",
    "            fo.loc[idx, \"Overlap\"] = \"\"\n",
    "            for delol in array[\"Overlap\"].split(\"-\"):\n",
    "                delol = int(delol)\n",
    "                arrayol = dfci.loc[delol]\n",
    "                newol = []\n",
    "                for ol in arrayol[\"Overlap\"].split(\"-\"):\n",
    "                    if ol!=str(idx):\n",
    "                        newol += [ol]\n",
    "                newol = \"-\".join(newol)\n",
    "                fo.loc[delol, \"Overlap\"] = newol\n",
    "                ci_list += [max(delol, idx)]\n",
    "        dfci = dfci.loc[ci_list]\n",
    "        dfci = dfci[dfci[\"Fully-Overlap\"]==False]\n",
    "else:\n",
    "    dfci = None\n",
    "\n",
    "# rawdata focuses on the word-level annotation\n",
    "# data1 focuses on the turn-taking behaviors\n",
    "# data2 focuses on the backchannels behaviors\n",
    "# data3 and dfci focus on the interjection behaviors\n",
    "os.makedirs(os.path.dirname(tablepath), exist_ok=True)\n",
    "data_dict = {'rawdata': rawdata, 'data1': data1, 'data2': data2, 'data3': data3, 'dfci': dfci}\n",
    "np.save(tablepath, data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746a83a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
