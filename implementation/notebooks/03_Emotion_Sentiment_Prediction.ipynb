{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Predicting Emotion and Sentiment\n",
    "\n",
    "This notebook shows you how to take the text responses from your dialogue table and predict:\n",
    "\n",
    "1. **Emotion labels** via our [Emotion Model](https://huggingface.co/j-hartmann/emotion-english-distilroberta-base)\n",
    "2. **Sentiment scores** via our [Sentiment Model](https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest)\n",
    "\n",
    "> **Before you begin:**  \n",
    "> Run all previous notebooks before proceeding.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from transformers import pipeline\n",
    "import glob\n",
    "\n",
    "import sys\n",
    "sys.path.append('../pyfiles/')\n",
    "from dialog import get_start_end_referencedf\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 504)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "tempfile = \"temp.wav\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "In this example, we predict text-based emotion and sentiment for each response. Please adjust the following variables:\n",
    "\n",
    "- `audiopath`: A string containing the path to your twoâ€‘channel audio file.  \n",
    "- `feature_dir`: A string specifying the directory where all preprocessed outputs are stored.  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "########## Adjustable Parameters ##########\n",
    "###########################################\n",
    "\n",
    "audiopath = \"../audio/sample.wav\"\n",
    "feature_dir = \"../audio/features/sample/\"\n",
    "\n",
    "###########################################\n",
    "###########################################\n",
    "###########################################\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device {device}\")\n",
    "\n",
    "### Classifiers ###\n",
    "model_path = \"j-hartmann/emotion-english-distilroberta-base\"\n",
    "text_emotion = pipeline(\"text-classification\", model=model_path, return_all_scores=True, device=device)\n",
    "\n",
    "model_path = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "text_sentiment = pipeline(\"sentiment-analysis\", model=model_path, tokenizer=model_path, device=device)\n",
    "\n",
    "print(\"#####################\")\n",
    "print(\"### Load all data ###\")\n",
    "print(\"#####################\")\n",
    "\n",
    "resultpath = feature_dir + \"whisper/\" + os.path.basename(audiopath[:-4]) + f\".npy\"\n",
    "laughpath = feature_dir + \"laughs/\" + os.path.basename(audiopath[:-4]) + f\".npy\"\n",
    "tablepath = laughpath.replace(\"laughs\", \"results\")\n",
    "\n",
    "a = np.load(tablepath, allow_pickle=True).item()\n",
    "rawdata, data1, data2, data3, dfci = a[\"rawdata\"], a[\"data1\"], a[\"data2\"], a[\"data3\"], a[\"dfci\"]\n",
    "dirname = feature_dir + \"classification_results/\"\n",
    "os.makedirs(dirname, exist_ok=True)\n",
    "\n",
    "print(\"##########################################################\")\n",
    "print(\"### Get classification results (emotion and sentiment) ###\")\n",
    "print(\"##########################################################\")\n",
    "\n",
    "for idx in range(len(data1)):\n",
    "    arrayturn = data1.iloc[idx]\n",
    "    startllm, endllm = get_start_end_referencedf(rawdata, arrayturn)\n",
    "    savepath = dirname + f'classificationresults_{startllm}_{endllm}.npy'\n",
    "    if os.path.exists(savepath):\n",
    "        continue\n",
    "\n",
    "    text = arrayturn[\"transcription\"]\n",
    "\n",
    "    # Text Classification\n",
    "    result_te = text_emotion(text)\n",
    "    result_ts = text_sentiment(text)\n",
    "\n",
    "    data_dict = {\"result_te\": result_te, \"result_ts\": result_ts}\n",
    "    np.save(savepath, data_dict)\n",
    "    \n",
    "print(\"##########################################\")\n",
    "print(\"##### Display Classification Results #####\")\n",
    "print(\"##########################################\")\n",
    "\n",
    "a = np.load(tablepath, allow_pickle=True).item()\n",
    "rawdata, data1, data2, data3, dfci = a[\"rawdata\"], a[\"data1\"], a[\"data2\"], a[\"data3\"], a[\"dfci\"]\n",
    "\n",
    "sentiment_score = False\n",
    "score_dir = {\n",
    "    \"Sentiment\": {\n",
    "        \"positive\": 10,\n",
    "        \"neutral\": 0,\n",
    "        \"negative\": -10,\n",
    "    },\n",
    "}\n",
    "\n",
    "tt_classes = [\"Sentiment\", \"Emotion\"]\n",
    "dirname = feature_dir + \"classification_results/\"\n",
    "keys = [\"_\".join(os.path.basename(a[:-4]).split(\"_\")[1:3]) for a in glob.glob(dirname+\"classificationresults_*.npy\")]\n",
    "keys.sort()\n",
    "\n",
    "udfst = data1.copy()\n",
    "udfst[\"Sentence-Emotion\"] = \"\"\n",
    "udfst[\"Sentence-Sentiment\"] = np.nan\n",
    "for key in keys:\n",
    "    # Obtain the prediction results\n",
    "    path = dirname + f\"classificationresults_{key}.npy\"\n",
    "    hey = np.load(path, allow_pickle=True).item()\n",
    "    result_te, result_ts = hey[\"result_te\"], hey[\"result_ts\"]\n",
    "    a = [a[\"label\"] for a in result_te[0]]\n",
    "    b = [a[\"score\"] for a in result_te[0]]\n",
    "    result_te = a[np.argmax(b)]\n",
    "    result_ts = result_ts[0][\"label\"]\n",
    "\n",
    "    # Insert the information to udfst\n",
    "    startllm, endllm = [int(a) for a in key.split(\"_\")]\n",
    "    try:\n",
    "        start = np.arange(len(udfst))[np.abs(rawdata.iloc[startllm][\"start\"]-udfst[\"start\"])<1e-5]\n",
    "        end = np.arange(len(udfst))[np.abs(rawdata.iloc[endllm][\"end\"]-udfst[\"end\"])<1e-5]\n",
    "        idx = list(set(list([udfst.iloc[a].name for a in start])) & set(list([udfst.iloc[a].name for a in end])))[0]\n",
    "        udfst.loc[idx, \"Sentence-Emotion\"] = result_te\n",
    "        udfst.loc[idx, \"Sentence-Sentiment\"] = score_dir[\"Sentiment\"][result_ts]\n",
    "        if not(sentiment_score):\n",
    "            udfst.loc[udfst[\"Sentence-Sentiment\"]==10, \"Sentence-Sentiment\"] = \"positive\"\n",
    "            udfst.loc[udfst[\"Sentence-Sentiment\"]==0, \"Sentence-Sentiment\"] = \"neutral\"\n",
    "            udfst.loc[udfst[\"Sentence-Sentiment\"]==-10, \"Sentence-Sentiment\"] = \"negative\"\n",
    "    except IndexError:\n",
    "        continue\n",
    "udfst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
