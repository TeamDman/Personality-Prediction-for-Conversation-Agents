{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Backchannel Type Prediction via Large Language Models (LLMs)\n",
    "\n",
    "This notebook shows you how to classify backchannel types—**“emotive”**, **“cognitive”**, or **“not backchannel”**—using OpenAI’s GPT models.\n",
    "\n",
    "> **Before you begin:**  \n",
    "> 1. Get an OpenAI API key and base URL.  \n",
    "> 2. Purchase the required quotas on [OpenAI’s API](https://openai.com/index/openai-api/).  \n",
    "> 3. Enter your credentials in the cell below (`api_key`, `api_base`).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "############### API Key of ChatGPT ###############\n",
    "##################################################\n",
    "\n",
    "# api_key = \"sk_...\"\n",
    "# api_base = \"\"\n",
    "\n",
    "##################################################\n",
    "##################################################\n",
    "##################################################\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../sho_util/pyfiles/\")\n",
    "from basic import get_bool_base_on_conditions\n",
    "\n",
    "sys.path.append('../pyfiles/')\n",
    "from dialog import get_start_end_referencedf, most_frequent\n",
    "from llmprediction import GetResult_Backchannel, get_past_future_conversation, get_prompt_backchannel\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 504)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "client = OpenAI(api_key=api_key, base_url=api_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "In this example, we predict backchannel types with a GPT model. To improve context, we include both past and future turns in the prompt. Please adjust the following variables as needed:\n",
    "\n",
    "- `audiopath`: A string containing the path to your two‑channel audio file.  \n",
    "- `feature_dir`: A string specifying the directory where all preprocessed outputs will be saved.  \n",
    "- `past_bc`: An integer specifying how many past turns to include in the prompt.  \n",
    "- `future_bc`: An integer specifying how many future turns to include in the prompt.  \n",
    "- `model`: A string naming the GPT model to use (e.g., `\"gpt-4o\"`). To add more models, edit the `gpt_api_no_stream` function in `./sho_util/pyfiles/gpt.py`.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "########## Adjustable Parameters ##########\n",
    "###########################################\n",
    "\n",
    "audiopath = \"../audio/sample.wav\"\n",
    "feature_dir = \"../audio/features/sample/\"\n",
    "past_bc = 2\n",
    "future_bc = 2\n",
    "model = \"gpt-4o\"\n",
    "\n",
    "###########################################\n",
    "###########################################\n",
    "###########################################\n",
    "\n",
    "repeatnum_bc = 1\n",
    "delete_toomuch_overlap = True\n",
    "get_response = True\n",
    "\n",
    "print(\"####################\")\n",
    "print(\"### Loading Data ###\")\n",
    "print(\"####################\")\n",
    "\n",
    "resultpath = feature_dir + \"whisper/\" + os.path.basename(audiopath[:-4]) + f\".npy\"\n",
    "laughpath = feature_dir + \"laughs/\" + os.path.basename(audiopath[:-4]) + f\".npy\"\n",
    "tablepath = laughpath.replace(\"laughs\", \"results\")\n",
    "\n",
    "a = np.load(tablepath, allow_pickle=True).item()\n",
    "rawdata, data1, data2, data3, dfci = a[\"rawdata\"], a[\"data1\"], a[\"data2\"], a[\"data3\"], a[\"dfci\"]\n",
    "\n",
    "### Backchanneling\n",
    "dfbc = data2[data2[\"BC-Candidates\"]]\n",
    "texts = [\"\"]*len(dfbc)\n",
    "dfbc[\"BC-Labels\"] = texts\n",
    "\n",
    "print(\"###################################\")\n",
    "print(\"### Backchannel Type Prediction ###\")\n",
    "print(\"###################################\")\n",
    "\n",
    "skips = []\n",
    "addname = \"\" if model==\"\" else \"_\"+model.split(\"-\")[-1]\n",
    "dirname = feature_dir + f'LLM_responses{addname}/' + os.path.basename(audiopath)[:-4] + \"/\"\n",
    "os.makedirs(dirname, exist_ok=True)\n",
    "dfturntaking = data1.copy()\n",
    "for i in range(len(dfbc)):\n",
    "    array = dfbc.iloc[i]\n",
    "    ol = array[\"Overlap\"].split(\"-\")[0]\n",
    "    arrayol = data2.iloc[int(ol)]\n",
    "\n",
    "    # Skip if we already have responses\n",
    "    startllm, endllm = get_start_end_referencedf(rawdata, array)\n",
    "    endllm = np.argmin(np.abs(rawdata[\"end\"]-array[\"end\"]))\n",
    "    a = glob.glob(dirname + f\"backchannel_{startllm}_{endllm}_*.npy\")\n",
    "    a.sort()\n",
    "    b = {int(os.path.basename(path).split(\"_\")[-1][:-4]): path for path in a}\n",
    "    iter_list = list(set(list(range(repeatnum_bc))) - set(list(b.keys())))\n",
    "    if len(iter_list)==0:\n",
    "        continue\n",
    "\n",
    "    # Get past and future conversation\n",
    "    start, end = get_start_end_referencedf(dfturntaking, arrayol)\n",
    "    start = np.argmin(np.abs(dfturntaking[\"start\"]-arrayol[\"start\"]))\n",
    "    end = np.argmin(np.abs(dfturntaking[\"end\"]-arrayol[\"end\"]))\n",
    "    dfpast = dfturntaking.iloc[:start].copy()\n",
    "    dffuture = dfturntaking.iloc[end+1:].copy()\n",
    "    dfpast, dffuture = get_past_future_conversation(dfpast, dffuture, past_bc, future_bc, delete_toomuch_overlap)\n",
    "\n",
    "    start, end = get_start_end_referencedf(rawdata, arrayol)\n",
    "    rangedf = rawdata.iloc[start:end+1].reset_index(drop=True)\n",
    "\n",
    "    start = np.argmin(np.abs(rangedf[\"start\"]-array[\"start\"]))\n",
    "    end = np.argmin(np.abs(rangedf[\"end\"]-array[\"end\"]))\n",
    "\n",
    "    a = rangedf.iloc[start:end+1]\n",
    "    a = a[get_bool_base_on_conditions(a, {\"speaker\":[array[\"speaker\"]]})]\n",
    "    b = \"{{{\" + (\" \".join(a[\"transcription\"].values)) + \"}}}\"\n",
    "    a = a.iloc[:1]\n",
    "    a[\"transcription\"] = b\n",
    "\n",
    "    df = rangedf[get_bool_base_on_conditions(rangedf, {\"speaker\":[arrayol[\"speaker\"]]})]\n",
    "    df[\"start\"] = df[\"end\"]\n",
    "    df = pd.concat([df, a], axis=0).sort_values(\"start\")\n",
    "    backchannel = array[\"transcription\"]\n",
    "    transcript = arrayol[\"transcription\"]\n",
    "    both = \" \".join(list(df.transcription))\n",
    "    current = [arrayol[\"speaker\"], array[\"speaker\"], backchannel, transcript, both]\n",
    "\n",
    "    prompt = get_prompt_backchannel(dfpast, dffuture, current)\n",
    "    if get_response:\n",
    "        for r in iter_list:\n",
    "            savepath = dirname + f'backchannel_{startllm}_{endllm}_{r}.npy'\n",
    "            if os.path.exists(savepath):\n",
    "                continue\n",
    "            response = GetResult_Backchannel(client, prompt, model)\n",
    "            np.save(savepath, response)\n",
    "\n",
    "print(\"#####################################\")\n",
    "print(\"##### Display Prediction Result #####\")\n",
    "print(\"#####################################\")\n",
    "\n",
    "a = np.load(tablepath, allow_pickle=True).item()\n",
    "rawdata, data1, data2, data3, dfci = a[\"rawdata\"], a[\"data1\"], a[\"data2\"], a[\"data3\"], a[\"dfci\"]\n",
    "dfbc = data2[data2[\"BC-Candidates\"]]\n",
    "model = \"gpt-4o\"\n",
    "addname = \"\" if model==\"\" else \"_\"+model.split(\"-\")[-1]\n",
    "dirname = feature_dir + f'LLM_responses{addname}/' + os.path.basename(audiopath)[:-4] + \"/\"\n",
    "tt_classes = [\"interjection type\"]\n",
    "keys = [\"_\".join(os.path.basename(a).split(\"_\")[1:3]) for a in glob.glob(dirname+\"backchannel_*_0.npy\")]\n",
    "keys.sort()\n",
    "\n",
    "udfbc = dfbc.copy()\n",
    "udfbc[\"BC-Labels\"] = \"\"\n",
    "for cl in tt_classes[1:]:\n",
    "    udfbc[\"BC-\"+cl] = \"\"\n",
    "for key in keys:\n",
    "    # Obtain the prediction results\n",
    "    paths = glob.glob(dirname+f\"backchannel_{key}_*.npy\")\n",
    "    results = {cl.lower(): [] for cl in tt_classes}\n",
    "    for path in paths:\n",
    "        a = np.load(path, allow_pickle=True).item()\n",
    "\n",
    "        for cl in tt_classes:\n",
    "            exist = cl in a\n",
    "            if not(exist):\n",
    "                cl = cl.lower()\n",
    "                exist = cl in a\n",
    "            if exist:\n",
    "                try:\n",
    "                    results[cl] += [a[cl].lower()]\n",
    "                except AttributeError:\n",
    "                    results[cl] += [key.lower() for key in a[cl]]\n",
    "\n",
    "    if len(results[tt_classes[0]])==0:\n",
    "        continue\n",
    "\n",
    "    summary = {}\n",
    "    for freq_key in [a.lower() for a in tt_classes[:2]]:\n",
    "        summary[freq_key] = most_frequent(results[freq_key])\n",
    "    for score_key in [a.lower() for a in tt_classes[2:]]:\n",
    "        summary[score_key] = np.mean([score_dir[score_key[0].upper()+score_key[1:]][a] for a in results[score_key]])\n",
    "\n",
    "    # Insert the information to udfbc\n",
    "    startllm, endllm = [int(a) for a in key.split(\"_\")]\n",
    "    try:\n",
    "        start = np.arange(len(udfbc))[np.abs(rawdata.iloc[startllm][\"start\"]-udfbc[\"start\"])<1e-5][0]\n",
    "        idx = udfbc.iloc[start].name\n",
    "        udfbc.loc[idx, \"BC-Labels\"] = summary[\"interjection type\"]\n",
    "        for cl in tt_classes[1:]:\n",
    "            udfbc.loc[idx, \"BC-\"+cl] = summary[cl.lower()]\n",
    "    except IndexError:\n",
    "        continue\n",
    "udfbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
