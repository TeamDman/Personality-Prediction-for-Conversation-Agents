{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Backchannel Type Prediction via Large Language Models (LLMs)\n",
    "\n",
    "This notebook shows you how to classify backchannel types—**“emotive”**, **“cognitive”**, or **“not backchannel”**—using OpenAI’s GPT models.\n",
    "\n",
    "> **Before you begin:**  \n",
    "> 1. Get an OpenAI API key and base URL.  \n",
    "> 2. Purchase the required quotas on [OpenAI’s API](https://openai.com/index/openai-api/).  \n",
    "> 3. Enter your credentials in the cell below (`api_key`, `api_base`).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "############### API Key of ChatGPT ###############\n",
    "##################################################\n",
    "\n",
    "# api_key = \"sk_...\"\n",
    "# api_base = \"\"\n",
    "\n",
    "##################################################\n",
    "##################################################\n",
    "##################################################\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../sho_util/pyfiles/\")\n",
    "from basic import get_bool_base_on_conditions\n",
    "\n",
    "sys.path.append('../pyfiles/')\n",
    "from dialog import get_start_end_referencedf, most_frequent\n",
    "from llmprediction import GetResult_Backchannel, get_past_future_conversation, get_prompt_backchannel\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 504)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# client = OpenAI(api_key=api_key, base_url=api_base)\n",
    "client = OpenAI(\n",
    "    base_url = 'http://localhost:11434/v1',\n",
    "    api_key='ollama', # required, but unused\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "In this example, we predict backchannel types with a GPT model. To improve context, we include both past and future turns in the prompt. Please adjust the following variables as needed:\n",
    "\n",
    "- `audiopath`: A string containing the path to your two‑channel audio file.  \n",
    "- `feature_dir`: A string specifying the directory where all preprocessed outputs will be saved.  \n",
    "- `past_bc`: An integer specifying how many past turns to include in the prompt.  \n",
    "- `future_bc`: An integer specifying how many future turns to include in the prompt.  \n",
    "- `model`: A string naming the GPT model to use (e.g., `\"gpt-4o\"`). To add more models, edit the `gpt_api_no_stream` function in `./sho_util/pyfiles/gpt.py`.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "### Loading Data ###\n",
      "####################\n",
      "###################################\n",
      "### Backchannel Type Prediction ###\n",
      "###################################\n",
      "#####################################\n",
      "##### Display Prediction Result #####\n",
      "#####################################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>speaker</th>\n",
       "      <th>transcription</th>\n",
       "      <th>duration</th>\n",
       "      <th>duration-before-talking</th>\n",
       "      <th>Overlap</th>\n",
       "      <th>Fully-Overlap</th>\n",
       "      <th>BC-Candidates</th>\n",
       "      <th>BC-Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.972</td>\n",
       "      <td>2.060062</td>\n",
       "      <td>B</td>\n",
       "      <td>hello</td>\n",
       "      <td>0.088062</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>not backchannel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13.380</td>\n",
       "      <td>13.780000</td>\n",
       "      <td>B</td>\n",
       "      <td>uh okay</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>2.780</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>cognitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>33.744</td>\n",
       "      <td>33.912000</td>\n",
       "      <td>A</td>\n",
       "      <td>oh</td>\n",
       "      <td>0.168000</td>\n",
       "      <td>2.204</td>\n",
       "      <td>18</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>emotive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>45.232</td>\n",
       "      <td>45.440000</td>\n",
       "      <td>B</td>\n",
       "      <td>yeah</td>\n",
       "      <td>0.208000</td>\n",
       "      <td>1.892</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>emotive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>50.796</td>\n",
       "      <td>51.100000</td>\n",
       "      <td>B</td>\n",
       "      <td>that's right</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>1.304</td>\n",
       "      <td>27</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>cognitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>90.480</td>\n",
       "      <td>90.820000</td>\n",
       "      <td>B</td>\n",
       "      <td>uh huh</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>7.560</td>\n",
       "      <td>40</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>95.316</td>\n",
       "      <td>95.700000</td>\n",
       "      <td>B</td>\n",
       "      <td>oh really</td>\n",
       "      <td>0.384000</td>\n",
       "      <td>4.496</td>\n",
       "      <td>40</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>cognitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>104.684</td>\n",
       "      <td>105.570000</td>\n",
       "      <td>B</td>\n",
       "      <td>yeah [Laugh]</td>\n",
       "      <td>0.886000</td>\n",
       "      <td>8.984</td>\n",
       "      <td>40</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>emotive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>107.460</td>\n",
       "      <td>107.780000</td>\n",
       "      <td>B</td>\n",
       "      <td>we did</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.890</td>\n",
       "      <td>40</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>not backchannel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>112.732</td>\n",
       "      <td>114.640000</td>\n",
       "      <td>B</td>\n",
       "      <td>no he was pretty good he never really chewed anything</td>\n",
       "      <td>1.908000</td>\n",
       "      <td>4.952</td>\n",
       "      <td>40</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>not backchannel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      start         end speaker  \\\n",
       "1     1.972    2.060062       B   \n",
       "9    13.380   13.780000       B   \n",
       "19   33.744   33.912000       A   \n",
       "25   45.232   45.440000       B   \n",
       "28   50.796   51.100000       B   \n",
       "41   90.480   90.820000       B   \n",
       "42   95.316   95.700000       B   \n",
       "43  104.684  105.570000       B   \n",
       "44  107.460  107.780000       B   \n",
       "45  112.732  114.640000       B   \n",
       "\n",
       "                                            transcription  duration  \\\n",
       "1                                                   hello  0.088062   \n",
       "9                                                 uh okay  0.400000   \n",
       "19                                                     oh  0.168000   \n",
       "25                                                   yeah  0.208000   \n",
       "28                                           that's right  0.304000   \n",
       "41                                                 uh huh  0.340000   \n",
       "42                                              oh really  0.384000   \n",
       "43                                           yeah [Laugh]  0.886000   \n",
       "44                                                 we did  0.320000   \n",
       "45  no he was pretty good he never really chewed anything  1.908000   \n",
       "\n",
       "    duration-before-talking Overlap  Fully-Overlap  BC-Candidates  \\\n",
       "1                     0.000       0           True           True   \n",
       "9                     2.780       8           True           True   \n",
       "19                    2.204      18           True           True   \n",
       "25                    1.892      24           True           True   \n",
       "28                    1.304      27           True           True   \n",
       "41                    7.560      40           True           True   \n",
       "42                    4.496      40           True           True   \n",
       "43                    8.984      40           True           True   \n",
       "44                    1.890      40           True           True   \n",
       "45                    4.952      40           True           True   \n",
       "\n",
       "          BC-Labels  \n",
       "1   not backchannel  \n",
       "9         cognitive  \n",
       "19          emotive  \n",
       "25          emotive  \n",
       "28        cognitive  \n",
       "41                   \n",
       "42        cognitive  \n",
       "43          emotive  \n",
       "44  not backchannel  \n",
       "45  not backchannel  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###########################################\n",
    "########## Adjustable Parameters ##########\n",
    "###########################################\n",
    "\n",
    "audiopath = \"../audio/sample.wav\"\n",
    "feature_dir = \"../audio/features/sample/\"\n",
    "past_bc = 2\n",
    "future_bc = 2\n",
    "# model = \"gpt-4o\"\n",
    "model = \"gemma3:12b\"\n",
    "\n",
    "###########################################\n",
    "###########################################\n",
    "###########################################\n",
    "\n",
    "repeatnum_bc = 1\n",
    "delete_toomuch_overlap = True\n",
    "get_response = True\n",
    "\n",
    "print(\"####################\")\n",
    "print(\"### Loading Data ###\")\n",
    "print(\"####################\")\n",
    "\n",
    "resultpath = feature_dir + \"whisper/\" + os.path.basename(audiopath[:-4]) + f\".npy\"\n",
    "laughpath = feature_dir + \"laughs/\" + os.path.basename(audiopath[:-4]) + f\".npy\"\n",
    "tablepath = laughpath.replace(\"laughs\", \"results\")\n",
    "\n",
    "a = np.load(tablepath, allow_pickle=True).item()\n",
    "rawdata, data1, data2, data3, dfci = a[\"rawdata\"], a[\"data1\"], a[\"data2\"], a[\"data3\"], a[\"dfci\"]\n",
    "\n",
    "### Backchanneling\n",
    "dfbc = data2[data2[\"BC-Candidates\"]]\n",
    "texts = [\"\"]*len(dfbc)\n",
    "dfbc[\"BC-Labels\"] = texts\n",
    "\n",
    "print(\"###################################\")\n",
    "print(\"### Backchannel Type Prediction ###\")\n",
    "print(\"###################################\")\n",
    "\n",
    "skips = []\n",
    "addname = \"\" if model==\"\" else \"_\"+model.split(\"-\")[-1].replace(\":\", \"_\")\n",
    "dirname = feature_dir + f'LLM_responses{addname}/' + os.path.basename(audiopath)[:-4] + \"/\"\n",
    "os.makedirs(dirname, exist_ok=True)\n",
    "dfturntaking = data1.copy()\n",
    "for i in range(len(dfbc)):\n",
    "    array = dfbc.iloc[i]\n",
    "    ol = array[\"Overlap\"].split(\"-\")[0]\n",
    "    arrayol = data2.iloc[int(ol)]\n",
    "\n",
    "    # Skip if we already have responses\n",
    "    startllm, endllm = get_start_end_referencedf(rawdata, array)\n",
    "    endllm = np.argmin(np.abs(rawdata[\"end\"]-array[\"end\"]))\n",
    "    a = glob.glob(dirname + f\"backchannel_{startllm}_{endllm}_*.npy\")\n",
    "    a.sort()\n",
    "    b = {int(os.path.basename(path).split(\"_\")[-1][:-4]): path for path in a}\n",
    "    iter_list = list(set(list(range(repeatnum_bc))) - set(list(b.keys())))\n",
    "    if len(iter_list)==0:\n",
    "        continue\n",
    "\n",
    "    # Get past and future conversation\n",
    "    start, end = get_start_end_referencedf(dfturntaking, arrayol)\n",
    "    start = np.argmin(np.abs(dfturntaking[\"start\"]-arrayol[\"start\"]))\n",
    "    end = np.argmin(np.abs(dfturntaking[\"end\"]-arrayol[\"end\"]))\n",
    "    dfpast = dfturntaking.iloc[:start].copy()\n",
    "    dffuture = dfturntaking.iloc[end+1:].copy()\n",
    "    dfpast, dffuture = get_past_future_conversation(dfpast, dffuture, past_bc, future_bc, delete_toomuch_overlap)\n",
    "\n",
    "    start, end = get_start_end_referencedf(rawdata, arrayol)\n",
    "    rangedf = rawdata.iloc[start:end+1].reset_index(drop=True)\n",
    "\n",
    "    start = np.argmin(np.abs(rangedf[\"start\"]-array[\"start\"]))\n",
    "    end = np.argmin(np.abs(rangedf[\"end\"]-array[\"end\"]))\n",
    "\n",
    "    a = rangedf.iloc[start:end+1]\n",
    "    a = a[get_bool_base_on_conditions(a, {\"speaker\":[array[\"speaker\"]]})]\n",
    "    b = \"{{{\" + (\" \".join(a[\"transcription\"].values)) + \"}}}\"\n",
    "    a = a.iloc[:1]\n",
    "    a[\"transcription\"] = b\n",
    "\n",
    "    df = rangedf[get_bool_base_on_conditions(rangedf, {\"speaker\":[arrayol[\"speaker\"]]})]\n",
    "    df[\"start\"] = df[\"end\"]\n",
    "    df = pd.concat([df, a], axis=0).sort_values(\"start\")\n",
    "    backchannel = array[\"transcription\"]\n",
    "    transcript = arrayol[\"transcription\"]\n",
    "    both = \" \".join(list(df.transcription))\n",
    "    current = [arrayol[\"speaker\"], array[\"speaker\"], backchannel, transcript, both]\n",
    "\n",
    "    prompt = get_prompt_backchannel(dfpast, dffuture, current)\n",
    "    if get_response:\n",
    "        for r in iter_list:\n",
    "            savepath = dirname + f'backchannel_{startllm}_{endllm}_{r}.npy'\n",
    "            if os.path.exists(savepath):\n",
    "                continue\n",
    "            response = GetResult_Backchannel(client, prompt, model)\n",
    "            np.save(savepath, response)\n",
    "\n",
    "print(\"#####################################\")\n",
    "print(\"##### Display Prediction Result #####\")\n",
    "print(\"#####################################\")\n",
    "\n",
    "a = np.load(tablepath, allow_pickle=True).item()\n",
    "rawdata, data1, data2, data3, dfci = a[\"rawdata\"], a[\"data1\"], a[\"data2\"], a[\"data3\"], a[\"dfci\"]\n",
    "dfbc = data2[data2[\"BC-Candidates\"]]\n",
    "model = \"gpt-4o\"\n",
    "addname = \"\" if model==\"\" else \"_\"+model.split(\"-\")[-1]\n",
    "dirname = feature_dir + f'LLM_responses{addname}/' + os.path.basename(audiopath)[:-4] + \"/\"\n",
    "tt_classes = [\"interjection type\"]\n",
    "keys = [\"_\".join(os.path.basename(a).split(\"_\")[1:3]) for a in glob.glob(dirname+\"backchannel_*_0.npy\")]\n",
    "keys.sort()\n",
    "\n",
    "udfbc = dfbc.copy()\n",
    "udfbc[\"BC-Labels\"] = \"\"\n",
    "for cl in tt_classes[1:]:\n",
    "    udfbc[\"BC-\"+cl] = \"\"\n",
    "for key in keys:\n",
    "    # Obtain the prediction results\n",
    "    paths = glob.glob(dirname+f\"backchannel_{key}_*.npy\")\n",
    "    results = {cl.lower(): [] for cl in tt_classes}\n",
    "    for path in paths:\n",
    "        a = np.load(path, allow_pickle=True).item()\n",
    "\n",
    "        for cl in tt_classes:\n",
    "            exist = cl in a\n",
    "            if not(exist):\n",
    "                cl = cl.lower()\n",
    "                exist = cl in a\n",
    "            if exist:\n",
    "                try:\n",
    "                    results[cl] += [a[cl].lower()]\n",
    "                except AttributeError:\n",
    "                    results[cl] += [key.lower() for key in a[cl]]\n",
    "\n",
    "    if len(results[tt_classes[0]])==0:\n",
    "        continue\n",
    "\n",
    "    summary = {}\n",
    "    for freq_key in [a.lower() for a in tt_classes[:2]]:\n",
    "        summary[freq_key] = most_frequent(results[freq_key])\n",
    "    for score_key in [a.lower() for a in tt_classes[2:]]:\n",
    "        summary[score_key] = np.mean([score_dir[score_key[0].upper()+score_key[1:]][a] for a in results[score_key]])\n",
    "\n",
    "    # Insert the information to udfbc\n",
    "    startllm, endllm = [int(a) for a in key.split(\"_\")]\n",
    "    try:\n",
    "        start = np.arange(len(udfbc))[np.abs(rawdata.iloc[startllm][\"start\"]-udfbc[\"start\"])<1e-5][0]\n",
    "        idx = udfbc.iloc[start].name\n",
    "        udfbc.loc[idx, \"BC-Labels\"] = summary[\"interjection type\"]\n",
    "        for cl in tt_classes[1:]:\n",
    "            udfbc.loc[idx, \"BC-\"+cl] = summary[cl.lower()]\n",
    "    except IndexError:\n",
    "        continue\n",
    "udfbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
